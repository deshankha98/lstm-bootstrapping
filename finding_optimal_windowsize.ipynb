{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yt head :\n",
      "0    393.0777\n",
      "1    391.6012\n",
      "2    390.7403\n",
      "3    391.8214\n",
      "4    394.3039\n",
      "Name: close, dtype: float64\n",
      "             yt        yt_       vt        yt1        yt2        yt3\n",
      "0      393.0777   391.6012  6031199   390.4551   393.7283   390.1698\n",
      "1      391.6012   390.7403  4330781   389.5892   391.8915   387.2619\n",
      "2      390.7403   391.8214  3714176   391.2659   394.3440   390.0747\n",
      "3      391.8214   394.3039  2393946   390.4551   393.0677   390.3750\n",
      "4      394.3039   396.8414  3466971   390.2549   394.7644   389.2739\n",
      "5      396.8414   403.8284  5453980   394.0937   397.0266   393.9285\n",
      "6      403.8284   396.6262  5857528   398.3930   403.9035   398.0376\n",
      "7      396.6262   398.1628  5522500   403.0527   404.8895   396.2929\n",
      "8      398.1628   400.2549  7008464   399.3990   403.1277   396.0056\n",
      "9      400.2549   395.7804  4103315   400.0296   401.0256   397.2969\n",
      "10     395.7804   395.4601  4602925   401.5512   404.6092   395.6402\n",
      "11     395.4601   400.2899  4399988   397.8975   398.3729   392.5922\n",
      "12     400.2899   401.0006  4047784   397.7974   402.7774   395.9506\n",
      "13     401.0006   403.4981  4526218   400.9506   403.8985   400.9155\n",
      "14     403.4981   411.1628  4346304   399.2989   403.9736   398.4731\n",
      "15     411.1628   419.7213  5545624   403.0527   411.8314   402.9025\n",
      "16     419.7213   416.1057  8079065   414.8795   420.4950   414.8644\n",
      "17     416.1057   416.7143  5739956   420.9330   422.4220   414.8194\n",
      "18     416.7143   416.1758  4101301   417.4470   418.7283   415.2048\n",
      "19     416.1758   417.8274  5817848   417.6673   417.8774   412.9375\n",
      "20     417.8274   414.2188  3186118   416.2608   420.2699   416.1658\n",
      "21     414.2188   413.0677  4012146   415.7704   416.3609   412.2468\n",
      "22     413.0677   411.1808  3279147   414.3639   415.7603   411.5662\n",
      "23     411.1808   407.5582  3298723   413.9085   413.9085   409.1037\n",
      "24     407.5582   404.2989  6191734   409.6592   410.5602   407.0767\n",
      "25     404.2989   406.0657  3672831   402.9025   406.7864   401.1357\n",
      "26     406.0657   407.7614  4191219   406.0256   410.0346   403.6282\n",
      "27     407.7614   406.0356  2924120   408.8234   409.1638   406.1257\n",
      "28     406.0356   405.5602  2930649   406.0506   408.8671   405.3299\n",
      "29     405.5602   405.2248  2973343   407.7774   408.0276   405.2248\n",
      "...         ...        ...      ...        ...        ...        ...\n",
      "1228  1068.8600  1065.8500   889446  1070.0000  1071.7200  1067.6400\n",
      "1229  1065.8500  1060.2000   918767  1068.6400  1068.8600  1058.6400\n",
      "1230  1060.2000  1055.9500  1116203  1066.6000  1068.2700  1058.3800\n",
      "1231  1055.9500  1053.4000   994249  1062.2500  1064.8400  1053.3800\n",
      "1232  1053.4000  1073.2100  1180340  1055.4900  1058.0500  1052.7000\n",
      "1233  1073.2100  1091.5200  1588268  1053.0200  1075.9800  1053.0200\n",
      "1234  1091.5200  1095.7600  1565945  1073.9300  1096.1000  1073.4300\n",
      "1235  1095.7600  1110.2900  1302569  1097.0900  1104.0800  1094.2600\n",
      "1236  1110.2900  1114.2100  1512526  1103.4500  1113.5800  1101.8000\n",
      "1237  1114.2100  1112.7900  1232221  1111.0000  1119.1600  1110.0000\n",
      "1238  1112.7900  1110.1400  1340381  1118.4400  1118.4400  1108.2000\n",
      "1239  1110.1400  1112.0500  1036655  1107.0000  1112.7800  1103.9800\n",
      "1240  1112.0500  1130.6500  1121216  1112.3100  1114.8500  1106.4800\n",
      "1241  1130.6500  1130.7000  1929306  1110.1000  1131.3000  1108.0100\n",
      "1242  1130.7000  1139.1000  1823100  1140.3100  1148.8800  1126.6600\n",
      "1243  1139.1000  1135.9700  1391510  1136.3600  1139.3200  1123.4900\n",
      "1244  1135.9700  1143.5000  1374873  1139.3500  1140.5900  1124.4600\n",
      "1245  1143.5000  1164.1600  1527554  1138.0300  1143.7800  1132.5000\n",
      "1246  1164.1600  1176.1700  1477520  1143.8200  1166.8800  1141.8200\n",
      "1247  1176.1700  1171.2900  1956865  1170.6200  1178.5100  1167.2500\n",
      "1248  1171.2900  1182.1400  1856429  1184.9800  1187.0500  1167.4000\n",
      "1249  1182.1400  1187.5600  1499247  1180.7100  1185.0000  1171.8400\n",
      "1250  1187.5600  1186.4800  2108502  1187.5300  1187.5600  1168.0300\n",
      "1251  1186.4800  1177.3700  1574708  1188.0000  1198.0000  1184.0600\n",
      "1252  1177.3700  1182.2200  1866883  1177.7200  1187.9300  1174.5100\n",
      "1253  1182.2200  1181.5900  1801135  1183.8100  1186.3200  1172.1000\n",
      "1254  1181.5900  1119.2000  3675709  1175.9900  1187.4500  1169.3600\n",
      "1255  1119.2000  1062.3900  5892122  1127.4200  1131.3000  1111.1700\n",
      "1256  1062.3900  1084.4300  4177469  1100.6100  1114.9900  1056.7400\n",
      "1257  1084.4300  1055.4100  3831524  1033.9800  1087.3800  1030.0100\n",
      "\n",
      "[1258 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 15s 18ms/step - loss: 0.1892\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0411\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0318\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.0318\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0319\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 13s 17ms/step - loss: 0.0319\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.0318\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0321\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0321\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0321\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0320\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.0320\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0322\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.0321\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0324\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0323\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0321\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0322\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0321\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0320\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0324\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0322\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0323\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.0324\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.0323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  100 0.17935582532475586\n",
      "window size rmse_test 100 21.12023945922453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 17s 22ms/step - loss: 0.1869\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0337\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0225\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0225\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0226\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0225\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.0224\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0225\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0226\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0226\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0225\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0225\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0227\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0225\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0228\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0227\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0225\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.0226\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0226\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0224\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0227\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.0226\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0227\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.0227\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.0226\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  120 0.15042761786392966\n",
      "window size rmse_test 120 34.138636143190844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.1833\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0299\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0233\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0232\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0232\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0232\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0231\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0232\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0231\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0233\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0230\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0231\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0233\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0231\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0235\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0233\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0232\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0232\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0232\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0231\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0234\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0232\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0235\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0233\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0232\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  140 0.15145624031221905\n",
      "window size rmse_test 140 47.51671784677069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.1766\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0193\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0143\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0139\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0140\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0140\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0142\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0142\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0142\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0144\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0142\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0143\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0144\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0145\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0145\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0146\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0146\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0147\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0145\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0146\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0150\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0147\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0149\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0149\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0148\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  160 0.12796640743510893\n",
      "window size rmse_test 160 21.438978661584983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 17s 22ms/step - loss: 0.1863\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0294\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0185\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0183\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0184\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.0183\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.0183\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0185\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0184\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0185\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0183\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0184\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.0186\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0184\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0186\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0186\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0185\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0185\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0184\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0183\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0185\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0185\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0187\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0185\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0185\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  180 0.1346400955450838\n",
      "window size rmse_test 180 24.501513275475403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.1713\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0301\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0155\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0156\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0156\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0157\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0156\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0159\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0159\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0161\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0162\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0162\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0164\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0162\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0164\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0165\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0164\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0167\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0166\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0167\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0169\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0167\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0168\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0169\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0169\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  200 0.1300674025611954\n",
      "window size rmse_test 200 28.847747716187566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 17s 22ms/step - loss: 0.1884\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0212\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0153\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0154\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0156\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0157\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0157\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0158\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0159\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0161\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0160\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0161\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0162\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0159\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0161\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0161\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0159\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0162\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0161\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0160\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0161\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0160\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0162\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0160\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0161\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  220 0.12519782496903747\n",
      "window size rmse_test 220 35.889414047029064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 19s 24ms/step - loss: 0.2021\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0262\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0147\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0145\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0147\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0147\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0146\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0147\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0147\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0147\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0146\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0146\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0148\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0146\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0147\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0149\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0146\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0148\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0147\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.0146\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0148\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0148\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.0150\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0148\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.0148\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  240 0.12094110098028939\n",
      "window size rmse_test 240 31.86679995993862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 21s 26ms/step - loss: 0.2199\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0291\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0172\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0174\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0176\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0177\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0178\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0178\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0181\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0183\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0182\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0185\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0185\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0188\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0189\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0193\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0190\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0190\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0190\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0194\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0198\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0198\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0200\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0200\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0198\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  260 0.140718094544324\n",
      "window size rmse_test 260 54.49658637594945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2131\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0230\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0108\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0107\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0108\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0108\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0108\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0109\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.0110\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0114\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0115\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0118\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0122\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0120\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0123\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0123\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0126\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0130\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0131\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0133\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0136\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0135\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0138\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0137\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0138\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  280 0.11595975413490213\n",
      "window size rmse_test 280 49.213539720971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 19s 23ms/step - loss: 0.2042\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0291\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0103\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0103\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0104\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0104\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0104\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0106\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0107\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0111\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0113\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0116\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0119\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0118\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0121\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0121\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0121\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 13s 17ms/step - loss: 0.0125\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0126\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0128\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0129\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0127\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0129\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0128\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  300 0.11130049906998192\n",
      "window size rmse_test 300 52.3884312633071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.1948\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0224\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0086\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0088\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0089\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.0091\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.0093\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0094\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0095\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0098\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0098\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.0100\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.0102\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.0104\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.0105\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0107\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0109\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.0110\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.0111\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.0110\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.0112\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0112\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0113\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.0114\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0111\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  320 0.09829777323517841\n",
      "window size rmse_test 320 12.413108096117389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.1979\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0269\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0114\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.0119\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 0.0124\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0126\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0130\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0133\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0136\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0142\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.0145\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0147\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0149\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0149\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0150\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0152\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0150\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0150\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0151\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0147\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0147\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0147\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0151\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0149\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0149\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  340 0.10994486853501483\n",
      "window size rmse_test 340 50.69783661867449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.2157\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0247\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0101\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0100\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0102\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0102\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0102\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0102\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0103\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0104\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0105\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0107\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0110\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0115\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0121\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0129\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0135\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0141\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0143\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0136\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0133\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0128\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0127\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0124\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0121\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  360 0.09948618094509104\n",
      "window size rmse_test 360 21.024209590214852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.2305\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0182\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0081\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0081\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0083\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0086\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0090\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0094\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0098\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0107\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0119\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0129\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0134\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0140\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0140\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0136\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0130\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0121\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0119\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0114\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0115\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0115\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.0117\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.0120\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.0118\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  380 0.09155233403841846\n",
      "window size rmse_test 380 35.46242517553335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1000, activation=\"tanh\", input_shape=(1, 1), recurrent_activation=\"hard_sigmoid\")`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "C:\\Users\\shankhajyoti\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.2364\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0114\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0046\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0045\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0045\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0045\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0045\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0046\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0045\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0046\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0046\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0047\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0050\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0054\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0065\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0082\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0110\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0142\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0151\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.0137\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.0112\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.0088\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0077\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.0067\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0063\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 1000)              4008000   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 4,009,001\n",
      "Trainable params: 4,009,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "window size  rmse_train  400 0.07510371067365754\n",
      "window size rmse_test 400 30.769568673897556\n",
      "window size, min rmse_test  320 12.413108096117389\n"
     ]
    }
   ],
   "source": [
    "#for varying windowsize in between 100 and 400 at jumps of 20 and calculating the rmse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import  Dropout\n",
    "\n",
    "\n",
    "df=pd.read_csv(\"C:\\\\Users\\\\shankhajyoti\\\\Dropbox\\\\Deepak\\\\GOOGL_data.csv\")\n",
    "data_csv=df\n",
    " \n",
    "#how many data we will use \n",
    "# (should not be more than dataset length )\n",
    "data_to_use= len(data_csv)\n",
    " \n",
    "# number of training data\n",
    "# should be less than data_to_use\n",
    "train_end =len(data_csv)-459\n",
    " \n",
    " \n",
    "total_data=len(data_csv)\n",
    " \n",
    "#most recent data is in the end \n",
    "#so need offset\n",
    "start=total_data - data_to_use\n",
    " \n",
    " \n",
    "#currently doing prediction only for 1 step ahead\n",
    "steps_to_predict =1\n",
    " \n",
    "  \n",
    "yt = data_csv.iloc [start:total_data ,4]    #Close price\n",
    "yt1 = data_csv.iloc [start:total_data ,1]   #Open\n",
    "yt2 = data_csv.iloc [start:total_data ,2]   #High\n",
    "yt3 = data_csv.iloc [start:total_data ,3]   #Low\n",
    "vt = data_csv.iloc [start:total_data ,5]    # volume\n",
    " \n",
    " \n",
    "print (\"yt head :\")\n",
    "print (yt.head())\n",
    " \n",
    "yt_ = yt.shift (-1)\n",
    "     \n",
    "data = pd.concat ([yt, yt_, vt, yt1, yt2, yt3], axis =1)\n",
    "data. columns = ['yt', 'yt_', 'vt', 'yt1', 'yt2', 'yt3']\n",
    "     \n",
    "data = data.dropna()\n",
    "     \n",
    "print (data)\n",
    "     \n",
    "# target variable - closed price\n",
    "# after shifting\n",
    "y = data ['yt_']\n",
    " \n",
    "        \n",
    "#       closed,  volume,   open,  high,   low    \n",
    "cols =['yt']\n",
    "x = data [cols]\n",
    "x_train_initial=x.loc[0:799,:] \n",
    "x_test_initial=x.loc[800:1257,:]   \n",
    "y_train_initial=y.loc[0:799]\n",
    "y_test_initial=y.loc[800:1257]\n",
    "min_rmse=float(\"inf\")\n",
    "\n",
    "\n",
    "for idx in range(5,21):\n",
    " scaler_x_train = preprocessing.MinMaxScaler ( feature_range =( -1, 1))\n",
    " x_train = np. array (x_train_initial).reshape ((len( x_train_initial) ,len(cols)))\n",
    " x_train_copy=x_train\n",
    " smoothing_window_size = 20*idx\n",
    " for di in range(0,800,smoothing_window_size):\n",
    "     scaler_x_train.fit(x_train[di:di+smoothing_window_size,:])\n",
    "     x_train[di:di+smoothing_window_size,:] = scaler_x_train.transform(x_train[di:di+smoothing_window_size,:])\n",
    "\n",
    " x_test = np. array (x_test_initial).reshape ((len( x_test_initial) ,len(cols)))\n",
    " x_test=scaler_x_train.transform(x_test)\n",
    "\n",
    " x_train = x_train.reshape (x_train. shape + (1,)) \n",
    " x_test = x_test.reshape (x_test. shape + (1,))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " scaler_y_train = preprocessing. MinMaxScaler ( feature_range =( -1, 1))\n",
    " y_train = np.array (y_train_initial).reshape ((len( y_train_initial), 1))\n",
    " y_train_copy=y_train\n",
    " smoothing_window_size = 20*idx\n",
    " for di in range(0,800,smoothing_window_size):\n",
    "     scaler_y_train.fit(y_train[di:di+smoothing_window_size,:])\n",
    "     y_train[di:di+smoothing_window_size,:] = scaler_y_train.transform(y_train[di:di+smoothing_window_size,:])\n",
    "\n",
    "#scaler_y_train.fit(y_train[di+smoothing_window_size:])\n",
    "#y_train[di+smoothing_window_size:] = scaler_y_train.transform(y_train[di+smoothing_window_size:])\n",
    " y_test = np. array (y_test_initial).reshape ((len( y_test_initial) ,1))\n",
    "#y_test=scaler_y_train.transform(y_test)\n",
    " \n",
    "     \n",
    "\n",
    "     \n",
    "     \n",
    " \n",
    "\n",
    " \n",
    " \n",
    " seed =2016\n",
    " np.random.seed (seed)\n",
    " fit1 = Sequential ()\n",
    " fit1.add (LSTM (  1000 , activation = 'tanh', inner_activation = 'hard_sigmoid' , input_shape =(len(cols), 1) ))\n",
    " fit1.add(Dropout(0.2))\n",
    " fit1.add (Dense (output_dim =1, activation = 'linear'))\n",
    " \n",
    " fit1.compile (loss =\"mean_squared_error\" , optimizer = \"adam\")   \n",
    " fit1.fit (x_train, y_train, batch_size =18, nb_epoch =25, shuffle = False)\n",
    " \n",
    " print (fit1.summary())\n",
    " \n",
    "\n",
    " x_train_copy = np.array(x_train_copy).reshape (x_train_copy. shape + (1,)) \n",
    "#x_train = scaler_x_train.inverse_transform (np. array (x_train). reshape ((len( x_train), len(cols)))) \n",
    "#y_train = scaler_y_train.inverse_transform (np. array (y_train). reshape ((len( y_train), 1)))    \n",
    " pred1 = fit1.predict (x_train_copy) \n",
    "#pred1 = scaler_y_train.inverse_transform (np. array (pred1). reshape ((len( pred1), 1)))\n",
    " pred1=np.array(pred1).reshape((len(pred1),1))\n",
    " sum=0.0\n",
    " for i in range(len(y_train)):\n",
    "     sum=sum+(y_train_copy[i,0]-pred1[i,0])**2\n",
    "\n",
    "    \n",
    " sum1=(sum/len(y_train))**0.5\n",
    "\n",
    "#x_test = scaler_x_train.inverse_transform (np. array (x_test). reshape ((len( x_test), len(cols))))\n",
    "#x_test = np.array(x_test).reshape (x_test. shape + (1,)) \n",
    "#y_test = scaler_y_train.inverse_transform (np. array (y_test). reshape ((len( y_test), 1)))\n",
    " pred1 = fit1.predict (x_test) \n",
    " pred1 = scaler_y_train.inverse_transform (np. array (pred1). reshape ((len( y_test), 1)))\n",
    " sum=0.0\n",
    " for i in range(len(y_test)):\n",
    "     sum=sum+(y_test[i,0]-pred1[i,0])**2\n",
    "\n",
    "    \n",
    " sum=(sum/len(y_test))**0.5\n",
    "\n",
    " print(\"window size  rmse_train \",smoothing_window_size,sum1)\n",
    " print(\"window size rmse_test\",smoothing_window_size,sum)\n",
    " if(min_rmse>=sum):\n",
    "     min_windowsize=smoothing_window_size\n",
    "     min_rmse=sum\n",
    "\n",
    "     \n",
    "    \n",
    " \n",
    "#fit1.summary()\n",
    "\n",
    " \n",
    "\n",
    "print(\"window size, min rmse_test \",min_windowsize,min_rmse) \n",
    " \n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
